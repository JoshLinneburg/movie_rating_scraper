{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started! \n",
    "\n",
    "As always, we start by importing the libraries we'll need for this little exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from functools import reduce\n",
    "from pandas.io.json import json_normalize\n",
    "import json\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import unicodedata as uni\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we'll set up some constants that will be driving our data analytics project here. The base URL for the website won't change, and we'll be using my username as the running example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://letterboxd.com/'\n",
    "account_name = 'JoshLinneburg'\n",
    "ratings_url = base_url + account_name + '/films/ratings/by/rating/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by scraping the webpage of interest: films by rating on my account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html_soup(url):\n",
    "    response = requests.get(url).text\n",
    "    soup = bs(response)\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = get_html_soup(ratings_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing we're going to do: Figure out how to itemize the films that have been rated *on a single page*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by splitting the page up into a list of movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_on_page = soup.findAll('ul', class_='poster-list -p150 -grid')[0].findAll('li')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to extract the stars and the URL from this HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User JoshLinneburg gave Chernobyl, which can be accessed here: /film/chernobyl/, a rating of ★★★★½ which translates to 4.5 on a numeric scale\n",
      "User JoshLinneburg gave The Empire Strikes Back, which can be accessed here: /film/the-empire-strikes-back/, a rating of ★★★★★ which translates to 5.0 on a numeric scale\n",
      "User JoshLinneburg gave The Shawshank Redemption, which can be accessed here: /film/the-shawshank-redemption/, a rating of ★★★★★ which translates to 5.0 on a numeric scale\n",
      "\n",
      "Remaining results hidden, you get the idea. \n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Let's only do the first 3 in our print() \n",
    "movies_to_show = min(len(movies_on_page), 3)\n",
    "\n",
    "for i in range(movies_to_show):\n",
    "    \n",
    "    # Might not use this later, but let's grab the name of the movie's image (which seems to be the movie name itself)\n",
    "    movie_name = movies_on_page[i].find('img')['alt'].strip()\n",
    "    \n",
    "    # Grab the movie_url\n",
    "    movie_url = movies_on_page[i].find('div', class_='poster film-poster really-lazy-load')['data-target-link']\n",
    "    \n",
    "    # Grab the raw star rating of the movie\n",
    "    user_movie_star_rating = movies_on_page[i].find('p').find('span').text.strip()\n",
    "    \n",
    "    # Convert the star rating to a numeric representation\n",
    "    # Note \"\\\" is used to breakup a statement into multiple lines\n",
    "    user_movie_nbr_rating = sum([float(user_movie_star_rating[i].replace('★', '1.0').replace('½', '0.5'))\\\n",
    "                                 for i in range(len(user_movie_star_rating))])\n",
    "    \n",
    "    # Print the results\n",
    "    print('User {0} gave {1}, which can be accessed here: {2}, a rating of {3} which translates to {4} on a numeric scale'\\\n",
    "          .format(account_name, movie_name, movie_url, user_movie_star_rating, user_movie_nbr_rating))\n",
    "    \n",
    "    # If we're at the last one, just print out a statement saying there's more we didn't show. \n",
    "    # We do minus 1 because our length goes to the value of 3 but list indexing in Python starts at 0\n",
    "    # So our \"i\" variable goes 0, 1, 2 for a total of 3 (our length)\n",
    "    if i == movies_to_show - 1:\n",
    "        print('\\nRemaining results hidden, you get the idea. \\n...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_movie_rating(html_soup):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Parses the HTML of a given film on https://letterboxd.com/YOURACCOUNTHERE/films/ratings/ and returns the rating\n",
    "    the user in question gave the film.\n",
    "    \n",
    "    Parameters:\n",
    "        html_soup (bs4 BeautifulSoup): BeautifulSoup representation of a given movie on a user's '/films/ratings/' page\n",
    "        This should be a single item in the list soup.findAll('ul', class_='poster-list -p150 -grid')[0].findAll('li')\n",
    "        \n",
    "    Returns:\n",
    "        movie_rating (float): Numeric representation of the star value assigned to a movie by a given user. \n",
    "        \n",
    "    Example:\n",
    "        url = 'https://letterboxd.com/joshlinneburg/films/ratings/' # URL string\n",
    "        soup = get_html_soup(url) # Parsed HTML for the URL string\n",
    "        movies_on_page = soup.findAll('ul', class_='poster-list -p150 -grid')[0].findAll('li') # List of 'li' classes on the page\n",
    "        get_user_movie_rating(movies_on_page[0]) # Single item in the list\n",
    "        \n",
    "        ...\n",
    "        \n",
    "        movie_rating = 5.0\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    raw_movie_rating = html_soup.find('p').find('span').text.strip()\n",
    "    movie_rating = sum([float(raw_movie_rating[i].replace('★', '1.0').replace('½', '0.5'))\\\n",
    "                        for i in range(len(raw_movie_rating))])\n",
    "    return movie_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_user_movie_rating(movies_on_page[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_url(html_soup):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Parses the HTML of a given film on https://letterboxd.com/YOURACCOUNTHERE/films/ratings/ and returns the URL\n",
    "    of the movie. \n",
    "    \n",
    "    Parameters:\n",
    "        html_soup (bs4 BeautifulSoup): BeautifulSoup representation of a given movie on a user's '/films/ratings' page\n",
    "        This should be a single item in the list soup.findAll('ul', class_='poster-list -p150 -grid')[0].findAll('li')\n",
    "    \n",
    "    Returns:\n",
    "        movie_url (str): Endpoint URL of a movie on letterboxd.com\n",
    "        Note: The URL does not contain the base_url ('https://letterboxd.com') and only begins at the /film/ endpoint. \n",
    "    \n",
    "    Example:\n",
    "        url = 'https://letterboxd.com/joshlinneburg/films/ratings/' # URL string\n",
    "        soup = get_html_soup(url) # Parsed HTML for the URL string\n",
    "        movies_on_page = soup.findAll('ul', class_='poster-list -p150 -grid')[0].findAll('li') # List of 'li' classes on the page\n",
    "        get_movie_url(movies_on_page[0]) # Single item in the list\n",
    "        \n",
    "        ...\n",
    "        \n",
    "        movie_url = /film/the-empire-strikes-back/\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    movie_url = html_soup.find('div', class_='poster film-poster really-lazy-load')['data-target-link']\n",
    "    return movie_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/film/chernobyl/'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_movie_url(movies_on_page[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up: Let's start scraping from a movie's page on here so we can access that detailed info about the film. Let's start with attributes that are on the Letterboxd website (title, actors, director, audience rating, genres) and then we can get crazy with items we'll need to scrape IMDb for (box office, release date, awards, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use *The Fellowship of the Ring* as our working example here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://letterboxd.com//film/the-lord-of-the-rings-the-fellowship-of-the-ring/'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lotr_fotr_url = 'https://letterboxd.com//film/the-lord-of-the-rings-the-fellowship-of-the-ring/'\n",
    "lotr_fotr_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up: scraping some data about the crew on a film. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crew_data(movie_url):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Given a URL to a movie on letterboxd.com, this function returns a nested dictionary containing data about the crewmembers\n",
    "    that worked on the movie. \n",
    "    \n",
    "    Parameters:\n",
    "        movie_url (str): URL to a film on letterboxd.com.\n",
    "        Note: Must be the full path of the URL including 'https://letterboxd.com/'\n",
    "        \n",
    "    Returns:\n",
    "        crew_dict (dict): Nested dictionary with data about the crew on a movie from letterboxd.com.\n",
    "        \n",
    "    Example: \n",
    "        movie_url = 'https://letterboxd.com/film/the-lord-of-the-rings-the-fellowship-of-the-ring/'\n",
    "        get_crew_data(movie_url)\n",
    "        \n",
    "        ...\n",
    "        \n",
    "        Output:\n",
    "        {'total_crew': 73,\n",
    "         'total_unique_crew': 70,\n",
    "         'crew_list': [\n",
    "                       {'crew_role': 'director',\n",
    "                        'number_assigned': 1,\n",
    "                        'crew_attributes': [\n",
    "                                            {'name': 'Peter Jackson',\n",
    "                                             'url': '/director/peter-jackson/'}\n",
    "                                           ]\n",
    "                       }, \n",
    "                       \n",
    "                       {'crew_role': 'producers',\n",
    "                        'number_assigned': 9,\n",
    "                        'crew_attributes': [\n",
    "                                            {'name': 'Barrie M. Osborne',\n",
    "                                             'url': '/producer/barrie-m-osborne/'},\n",
    "                                            {'name': 'Peter Jackson', \n",
    "                                             'url': '/producer/peter-jackson/'},\n",
    "                                            {'name': 'Bob Weinstein', \n",
    "                                             'url': '/producer/bob-weinstein/'},\n",
    "                                            {'name': 'Harvey Weinstein', \n",
    "                                             'url': '/producer/harvey-weinstein/'},\n",
    "                                            {'name': 'Mark Ordesky', \n",
    "                                             'url': '/producer/mark-ordesky/'},\n",
    "                                            {'name': 'Michael Lynne', \n",
    "                                             'url': '/producer/michael-lynne/'},\n",
    "                                            {'name': 'Fran Walsh', \n",
    "                                             'url': '/producer/fran-walsh/'},\n",
    "                                            {'name': 'Robert Shaye', \n",
    "                                             'url': '/producer/robert-shaye/'},\n",
    "                                            {'name': 'Tim Sanders', \n",
    "                                             'url': '/producer/tim-sanders/'}\n",
    "                                           ]\n",
    "                       },\n",
    "                       \n",
    "                       ... \n",
    "                      \n",
    "                      ]\n",
    "        }\n",
    "        \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    soup = get_html_soup(movie_url)\n",
    "    \n",
    "    # Categories (Director, Producers, Writers, etc.) of crewmembers available\n",
    "    crew_roles_avail = soup.find('div', class_='tabbed-content-block column-block').findAll('span')\n",
    "\n",
    "    # Same information in a list without HTML tags\n",
    "    crew_roles_avail_list = [tag.text.lower() for tag in crew_roles_avail]\n",
    "\n",
    "    # Init the crew list\n",
    "    crew_dict = {}\n",
    "    crew_list = []\n",
    "    total_crew_counter = 0\n",
    "    crew_names_list = []\n",
    "    unique_crew_names = set()\n",
    "\n",
    "    for i in range(len(crew_roles_avail_list)):\n",
    "        crew_role_dict = {}\n",
    "\n",
    "        # Role is just whatever role we're on \n",
    "        crew_role_dict['crew_role'] = crew_roles_avail_list[i]\n",
    "\n",
    "        # Find the list of names and URLs for a given role\n",
    "        crew_attributes_list = soup.find('div', class_='tabbed-content-block column-block').findAll('div')[i].findAll('a')\n",
    "\n",
    "        # Iterate on our counter\n",
    "        total_crew_counter += len(crew_attributes_list)\n",
    "\n",
    "        # How many people are assigned to this role\n",
    "        crew_role_dict['number_assigned'] = len(crew_attributes_list)\n",
    "\n",
    "        # Init an \"inner\" list - a list of dictionaries containing the name and URL of each crewmember\n",
    "        inner_crew_list = [] \n",
    "\n",
    "        for j in range(len(crew_attributes_list)):\n",
    "            inner_crew_dict = {}\n",
    "\n",
    "            # Crewmember name\n",
    "            inner_crew_dict['name'] = crew_attributes_list[j].text\n",
    "            crew_names_list.append(crew_attributes_list[j].text)\n",
    "\n",
    "            # Crewmember URL\n",
    "            inner_crew_dict['url'] = crew_attributes_list[j]['href']\n",
    "\n",
    "            # Append this inner list to the inner dictionary\n",
    "            inner_crew_list.append(inner_crew_dict)\n",
    "\n",
    "        # Add our completed inner list to the outer dictionary\n",
    "        crew_role_dict['crew_attributes'] = inner_crew_list\n",
    "\n",
    "        # Append to our growing list\n",
    "        crew_list.append(crew_role_dict)\n",
    "\n",
    "    # Gets the total number of crewmembers listed\n",
    "    crew_dict['total_crew'] = total_crew_counter\n",
    "\n",
    "    # Gets the total number of unique crewmembers listed\n",
    "    for name in crew_names_list:\n",
    "        if name not in unique_crew_names:\n",
    "            unique_crew_names.add(name)\n",
    "\n",
    "    crew_dict['total_unique_crew'] = len(unique_crew_names)\n",
    "\n",
    "    crew_dict['crew_list'] = crew_list\n",
    "    \n",
    "    return crew_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_crew': 73,\n",
       " 'total_unique_crew': 70,\n",
       " 'crew_list': [{'crew_role': 'director',\n",
       "   'number_assigned': 1,\n",
       "   'crew_attributes': [{'name': 'Peter Jackson',\n",
       "     'url': '/director/peter-jackson/'}]},\n",
       "  {'crew_role': 'producers',\n",
       "   'number_assigned': 9,\n",
       "   'crew_attributes': [{'name': 'Barrie M. Osborne',\n",
       "     'url': '/producer/barrie-m-osborne/'},\n",
       "    {'name': 'Peter Jackson', 'url': '/producer/peter-jackson/'},\n",
       "    {'name': 'Bob Weinstein', 'url': '/producer/bob-weinstein/'},\n",
       "    {'name': 'Harvey Weinstein', 'url': '/producer/harvey-weinstein/'},\n",
       "    {'name': 'Mark Ordesky', 'url': '/producer/mark-ordesky/'},\n",
       "    {'name': 'Michael Lynne', 'url': '/producer/michael-lynne/'},\n",
       "    {'name': 'Fran Walsh', 'url': '/producer/fran-walsh/'},\n",
       "    {'name': 'Robert Shaye', 'url': '/producer/robert-shaye/'},\n",
       "    {'name': 'Tim Sanders', 'url': '/producer/tim-sanders/'}]},\n",
       "  {'crew_role': 'writers',\n",
       "   'number_assigned': 4,\n",
       "   'crew_attributes': [{'name': 'Peter Jackson',\n",
       "     'url': '/writer/peter-jackson/'},\n",
       "    {'name': 'J.R.R. Tolkien', 'url': '/writer/jrr-tolkien/'},\n",
       "    {'name': 'Fran Walsh', 'url': '/writer/fran-walsh/'},\n",
       "    {'name': 'Philippa Boyens', 'url': '/writer/philippa-boyens/'}]},\n",
       "  {'crew_role': 'editor',\n",
       "   'number_assigned': 1,\n",
       "   'crew_attributes': [{'name': 'John Gilbert',\n",
       "     'url': '/editor/john-gilbert-4/'}]},\n",
       "  {'crew_role': 'cinematography',\n",
       "   'number_assigned': 1,\n",
       "   'crew_attributes': [{'name': 'Andrew Lesnie',\n",
       "     'url': '/cinematography/andrew-lesnie-1/'}]},\n",
       "  {'crew_role': 'production design',\n",
       "   'number_assigned': 11,\n",
       "   'crew_attributes': [{'name': 'Grant Major',\n",
       "     'url': '/production-design/grant-major/'},\n",
       "    {'name': 'Joe Bleakley', 'url': '/production-design/joe-bleakley/'},\n",
       "    {'name': 'Philip Ivey', 'url': '/production-design/philip-ivey/'},\n",
       "    {'name': 'Rob Outterside', 'url': '/production-design/rob-outterside/'},\n",
       "    {'name': 'Mark Robins', 'url': '/production-design/mark-robins/'},\n",
       "    {'name': 'Alan Lee', 'url': '/production-design/alan-lee-1/'},\n",
       "    {'name': 'John Howe', 'url': '/production-design/john-howe-1/'},\n",
       "    {'name': 'Jules Cook', 'url': '/production-design/jules-cook/'},\n",
       "    {'name': 'Chris Hennah', 'url': '/production-design/chris-hennah/'},\n",
       "    {'name': 'Jacqui Allen', 'url': '/production-design/jacqui-allen/'},\n",
       "    {'name': 'Ross McGarva', 'url': '/production-design/ross-mcgarva-1/'}]},\n",
       "  {'crew_role': 'visual effects',\n",
       "   'number_assigned': 11,\n",
       "   'crew_attributes': [{'name': 'Mark O. Forker',\n",
       "     'url': '/visual-effects/mark-o-forker/'},\n",
       "    {'name': 'Paul Lasaine', 'url': '/visual-effects/paul-lasaine/'},\n",
       "    {'name': 'Mark Stetson', 'url': '/visual-effects/mark-stetson/'},\n",
       "    {'name': 'Charlie McClellan', 'url': '/visual-effects/charlie-mcclellan/'},\n",
       "    {'name': 'Geoff Dixon', 'url': '/visual-effects/geoff-dixon/'},\n",
       "    {'name': 'Dean Lyon', 'url': '/visual-effects/dean-lyon/'},\n",
       "    {'name': \"Kelly L'Estrange\", 'url': '/visual-effects/kelly-lestrange/'},\n",
       "    {'name': 'Jim Rygiel', 'url': '/visual-effects/jim-rygiel/'},\n",
       "    {'name': 'Eileen Moran', 'url': '/visual-effects/eileen-moran/'},\n",
       "    {'name': 'Randall William Cook',\n",
       "     'url': '/visual-effects/randall-william-cook/'},\n",
       "    {'name': 'Steen Bech', 'url': '/visual-effects/steen-bech/'}]},\n",
       "  {'crew_role': 'composer',\n",
       "   'number_assigned': 1,\n",
       "   'crew_attributes': [{'name': 'Howard Shore',\n",
       "     'url': '/composer/howard-shore/'}]},\n",
       "  {'crew_role': 'sound',\n",
       "   'number_assigned': 13,\n",
       "   'crew_attributes': [{'name': 'Christopher Boyes',\n",
       "     'url': '/sound/christopher-boyes/'},\n",
       "    {'name': 'Brent Burge', 'url': '/sound/brent-burge/'},\n",
       "    {'name': 'David Farmer', 'url': '/sound/david-farmer/'},\n",
       "    {'name': 'Gethin Creagh', 'url': '/sound/gethin-creagh/'},\n",
       "    {'name': 'John McKay', 'url': '/sound/john-mckay-2/'},\n",
       "    {'name': 'Ethan van der Ryn', 'url': '/sound/ethan-van-der-ryn/'},\n",
       "    {'name': 'Michael Semanick', 'url': '/sound/michael-semanick/'},\n",
       "    {'name': 'Tim Nielsen', 'url': '/sound/tim-nielsen/'},\n",
       "    {'name': 'Mike Hopkins', 'url': '/sound/mike-hopkins-1/'},\n",
       "    {'name': 'Ken Saville', 'url': '/sound/ken-saville/'},\n",
       "    {'name': 'Craig Tomlinson', 'url': '/sound/craig-tomlinson/'},\n",
       "    {'name': 'Hammond Peek', 'url': '/sound/hammond-peek/'},\n",
       "    {'name': 'Malcolm Cromie', 'url': '/sound/malcolm-cromie/'}]},\n",
       "  {'crew_role': 'costumes',\n",
       "   'number_assigned': 2,\n",
       "   'crew_attributes': [{'name': 'Ngila Dickson',\n",
       "     'url': '/costumes/ngila-dickson/'},\n",
       "    {'name': 'Richard Taylor', 'url': '/costumes/richard-taylor-4/'}]},\n",
       "  {'crew_role': 'make-up',\n",
       "   'number_assigned': 19,\n",
       "   'crew_attributes': [{'name': 'Jeremy Woodhead',\n",
       "     'url': '/make-up/jeremy-woodhead/'},\n",
       "    {'name': 'Rick Findlater', 'url': '/make-up/rick-findlater/'},\n",
       "    {'name': 'Margaret Aston', 'url': '/make-up/margaret-aston/'},\n",
       "    {'name': 'Noreen Wilkie', 'url': '/make-up/noreen-wilkie/'},\n",
       "    {'name': 'Janine Schneider', 'url': '/make-up/janine-schneider/'},\n",
       "    {'name': 'Nancy Hennah', 'url': '/make-up/nancy-hennah/'},\n",
       "    {'name': 'Catherine Maguire', 'url': '/make-up/catherine-maguire/'},\n",
       "    {'name': 'Davina Lamont', 'url': '/make-up/davina-lamont/'},\n",
       "    {'name': 'Linda Wall', 'url': '/make-up/linda-wall/'},\n",
       "    {'name': 'Vivienne MacGillicuddy',\n",
       "     'url': '/make-up/vivienne-macgillicuddy/'},\n",
       "    {'name': 'Kerryn Flewell-Smith', 'url': '/make-up/kerryn-flewell-smith/'},\n",
       "    {'name': 'Mark Kinaston-Smith', 'url': '/make-up/mark-kinaston-smith/'},\n",
       "    {'name': 'Emma Moncrieff', 'url': '/make-up/emma-moncrieff/'},\n",
       "    {'name': 'Allie Rutherford', 'url': '/make-up/allie-rutherford/'},\n",
       "    {'name': 'Lenore Stewart', 'url': '/make-up/lenore-stewart/'},\n",
       "    {'name': 'Tanya Travis', 'url': '/make-up/tanya-travis/'},\n",
       "    {'name': 'Tera Treanor', 'url': '/make-up/tera-treanor/'},\n",
       "    {'name': 'Bronwyn Knott', 'url': '/make-up/bronwyn-knott/'},\n",
       "    {'name': 'Laurelle Ziento', 'url': '/make-up/laurelle-ziento/'}]}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crew_dict = get_crew_data(lotr_fotr_url)\n",
    "crew_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about some prototype code for when we need to convert this into a Pandas dataframe? Let's assume we only care about a few different crew roles and only want the \"main\" person (the first person listed) in that role returned. How would we do something like this? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peter Jackson: director 0\n",
      "Barrie M. Osborne: producer 1\n",
      "Peter Jackson: writer 2\n",
      "Howard Shore: composer 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'director': 'Peter Jackson',\n",
       " 'producer': 'Barrie M. Osborne',\n",
       " 'writer': 'Peter Jackson',\n",
       " 'composer': 'Howard Shore'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crew_wanted = ['director', 'producer', 'writer', 'composer']\n",
    "\n",
    "condensed_crew_dict = {}\n",
    "condensed_crew_list = crew_dict['crew_list']\n",
    "\n",
    "for i in range(len(condensed_crew_list)):\n",
    "    for j in range(len(crew_wanted)):\n",
    "        if crew_wanted[j] in condensed_crew_list[i]['crew_role']:\n",
    "            condensed_crew_dict[crew_wanted[j]] = condensed_crew_list[i]['crew_attributes'][0]['name']\n",
    "            print(condensed_crew_list[i]['crew_attributes'][0]['name'] + ': ' + crew_wanted[j] + ' ' + str(i))\n",
    "            \n",
    "condensed_crew_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like that would work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab more information about the movie... How about the cast?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cast_data(movie_url, max_cast_to_return = 15):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Given a URL to a movie on letterboxd.com, this function returns a nested dictionary containing data about the cast \n",
    "    that played in the movie. \n",
    "    \n",
    "    Parameters:\n",
    "        movie_url (str): URL to a film on letterboxd.com.\n",
    "        Note: Must be the full path of the URL including 'https://letterboxd.com/'\n",
    "        \n",
    "        max_cast_to_return: Max number of cast members to include in output. Default is 15. \n",
    "        \n",
    "    Returns:\n",
    "        cast_dict (dict): Nested dictionary which contains data about the cast of a movie on Letterboxd.com\n",
    "        \n",
    "    Example: \n",
    "        movie_url = 'https://letterboxd.com/film/the-lord-of-the-rings-the-fellowship-of-the-ring/'\n",
    "        get_cast_data(movie_url)\n",
    "        \n",
    "        ...\n",
    "        \n",
    "        Output: \n",
    "        {'total_cast': 80,\n",
    "         'cast_list': [\n",
    "                       {'actor_seq_nbr': 0,\n",
    "                        'actor_name': 'Elijah Wood',\n",
    "                        'actor_role': 'Frodo Baggins',\n",
    "                        'actor_url': '/actor/elijah-wood/'\n",
    "                       },\n",
    "\n",
    "                       {'actor_seq_nbr': 1,\n",
    "                        'actor_name': 'Ian McKellen',\n",
    "                        'actor_role': 'Gandalf the Grey',\n",
    "                        'actor_url': '/actor/ian-mckellen/'\n",
    "                       },\n",
    "                       \n",
    "                       ...\n",
    "                      \n",
    "                      ]\n",
    "        }    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    soup = get_html_soup(movie_url)\n",
    "    \n",
    "    available_cast = soup.find('div', class_='cast-list text-sluglist').findAll('a', class_='text-slug tooltip')\n",
    "\n",
    "    cast_dict = {}\n",
    "    cast_list = []\n",
    "    cast_names_list = []\n",
    "    unique_cast_names = set()\n",
    "\n",
    "    for i in range(min(len(available_cast), max_cast_to_return)):\n",
    "        \n",
    "        try:\n",
    "            cast_attr_dict = {}\n",
    "            cast_attr_dict['actor_seq_nbr'] = i\n",
    "            cast_attr_dict['actor_name'] = available_cast[i].text\n",
    "            cast_attr_dict['actor_role'] = available_cast[i]['title']\n",
    "            cast_attr_dict['actor_url'] = available_cast[i]['href']\n",
    "            unique_cast_names.add(available_cast[i].text)\n",
    "            cast_list.append(cast_attr_dict)\n",
    "        except:\n",
    "            string_to_print = 'Failed on the ' + str(i) + \"'th execution of the loop.\\n\"\n",
    "            string_to_print = string_to_print + 'The movie passed in:' + movie_url +'.\\n'\n",
    "\n",
    "    # Total number of castmembers\n",
    "    cast_dict['total_cast'] = len(available_cast)\n",
    "\n",
    "    # List of castmembers\n",
    "    cast_dict['cast_list'] = cast_list\n",
    "    \n",
    "    return cast_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_cast': 80,\n",
       " 'cast_list': [{'actor_seq_nbr': 0,\n",
       "   'actor_name': 'Elijah Wood',\n",
       "   'actor_role': 'Frodo Baggins',\n",
       "   'actor_url': '/actor/elijah-wood/'},\n",
       "  {'actor_seq_nbr': 1,\n",
       "   'actor_name': 'Ian McKellen',\n",
       "   'actor_role': 'Gandalf the Grey',\n",
       "   'actor_url': '/actor/ian-mckellen/'},\n",
       "  {'actor_seq_nbr': 2,\n",
       "   'actor_name': 'Viggo Mortensen',\n",
       "   'actor_role': 'Aragorn',\n",
       "   'actor_url': '/actor/viggo-mortensen/'},\n",
       "  {'actor_seq_nbr': 3,\n",
       "   'actor_name': 'Sean Astin',\n",
       "   'actor_role': 'Samwise \"Sam\" Gamgee',\n",
       "   'actor_url': '/actor/sean-astin/'},\n",
       "  {'actor_seq_nbr': 4,\n",
       "   'actor_name': 'Liv Tyler',\n",
       "   'actor_role': 'Arwen Evenstar',\n",
       "   'actor_url': '/actor/liv-tyler/'},\n",
       "  {'actor_seq_nbr': 5,\n",
       "   'actor_name': 'Orlando Bloom',\n",
       "   'actor_role': 'Legolas',\n",
       "   'actor_url': '/actor/orlando-bloom/'},\n",
       "  {'actor_seq_nbr': 6,\n",
       "   'actor_name': 'John Rhys-Davies',\n",
       "   'actor_role': 'Gimli',\n",
       "   'actor_url': '/actor/john-rhys-davies/'},\n",
       "  {'actor_seq_nbr': 7,\n",
       "   'actor_name': 'Dominic Monaghan',\n",
       "   'actor_role': 'Meriadoc \"Merry\" Brandybuck',\n",
       "   'actor_url': '/actor/dominic-monaghan/'},\n",
       "  {'actor_seq_nbr': 8,\n",
       "   'actor_name': 'Billy Boyd',\n",
       "   'actor_role': 'Peregrin \"Pippin\" Took',\n",
       "   'actor_url': '/actor/billy-boyd/'},\n",
       "  {'actor_seq_nbr': 9,\n",
       "   'actor_name': 'Sean Bean',\n",
       "   'actor_role': 'Boromir',\n",
       "   'actor_url': '/actor/sean-bean/'},\n",
       "  {'actor_seq_nbr': 10,\n",
       "   'actor_name': 'Andy Serkis',\n",
       "   'actor_role': 'Gollum / Witch-king of Angmar (voice)',\n",
       "   'actor_url': '/actor/andy-serkis/'},\n",
       "  {'actor_seq_nbr': 11,\n",
       "   'actor_name': 'Cate Blanchett',\n",
       "   'actor_role': 'Galadriel',\n",
       "   'actor_url': '/actor/cate-blanchett/'},\n",
       "  {'actor_seq_nbr': 12,\n",
       "   'actor_name': 'Christopher Lee',\n",
       "   'actor_role': 'Saruman',\n",
       "   'actor_url': '/actor/christopher-lee/'},\n",
       "  {'actor_seq_nbr': 13,\n",
       "   'actor_name': 'Hugo Weaving',\n",
       "   'actor_role': 'Elrond',\n",
       "   'actor_url': '/actor/hugo-weaving/'},\n",
       "  {'actor_seq_nbr': 14,\n",
       "   'actor_name': 'Ian Holm',\n",
       "   'actor_role': 'Bilbo Baggins',\n",
       "   'actor_url': '/actor/ian-holm/'}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cast_dict = get_cast_data(lotr_fotr_url)\n",
    "cast_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can probably do something similar to above and only returne the first 3, 5, 10, etc. members of the cast when we go to toss this into a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elijah Wood\n",
      "Ian McKellen\n",
      "Viggo Mortensen\n",
      "Sean Astin\n",
      "Liv Tyler\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while i < 5:\n",
    "    print(cast_dict['cast_list'][i]['actor_name'])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the title next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_title(movie_url):\n",
    "    \n",
    "    '''\n",
    "    Given a URL to a movie on letterboxd.com, this function returns the title of the movie.\n",
    "    \n",
    "    Parameters:\n",
    "        movie_url (str): URL to a film on letterboxd.com.\n",
    "        \n",
    "    Returns:\n",
    "        movie_title (str): Title to the film in question. \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    soup = get_html_soup(movie_url)\n",
    "    \n",
    "    movie_title = soup.find('h1', class_='headline-1 js-widont prettify').text.strip()\n",
    "    return movie_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Lord of the Rings: The Fellowship of the Ring'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_title = get_movie_title(lotr_fotr_url)\n",
    "movie_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we'll also grab the movie genres while we're at it too - this one is going to return a list of genres instead of a single value or a dictionary. Again, a good candidate for breaking this out into multiple columns in a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_genres(movie_url):\n",
    "    \n",
    "    '''\n",
    "    Given a URL to a movie on letterboxd.com, this function returns the title of the movie.\n",
    "    \n",
    "    Parameters:\n",
    "        movie_url (str): URL to a film on letterboxd.com.\n",
    "        \n",
    "    Returns:\n",
    "        movie_genres_list (list): List of genres for film on letterboxd.com.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    soup = get_html_soup(movie_url)\n",
    "    \n",
    "    movie_genres_list = [tag.text for tag in soup.find('div', class_='text-sluglist capitalize').findAll('a')]\n",
    "    return movie_genres_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['action', 'adventure', 'fantasy']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_genres = get_movie_genres(lotr_fotr_url)\n",
    "movie_genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is for the average rating among all raters of the movie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_avg_rating(movie_url):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Given a URL to a movie on letterboxd.com, this function returns the average rating of the movie among all users.\n",
    "    \n",
    "    Parameters:\n",
    "        movie_url (str): URL to a film on letterboxd.com.\n",
    "        \n",
    "    Returns:\n",
    "        movie_avg_rating (str): Average rating of the movie in question. \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    soup = get_html_soup(movie_url)\n",
    "    soup = bs(requests.get(base_url + soup.find('aside', class_='sidebar').find('div', class_='js-csi')['data-src']).text)\n",
    "    \n",
    "    try:\n",
    "        movie_avg_rating = soup.find('span', class_='average-rating').find('a').text\n",
    "    except:\n",
    "        return 'Not available'\n",
    "    \n",
    "    return movie_avg_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.3'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_avg_rating = get_movie_avg_rating(lotr_fotr_url)\n",
    "movie_avg_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here we're actually getting data on all the ratings for the movie - so we can tell what percentage of people rated it above or below our user or the average. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_rating_counts(movie_url):\n",
    "\n",
    "    '''\n",
    "\n",
    "    Given a URL to a movie on letterboxd.com, this function returns the average rating of the movie among all users.\n",
    "\n",
    "    Parameters:\n",
    "        movie_url (str): URL to a film on letterboxd.com.\n",
    "\n",
    "    Returns:\n",
    "        movie_avg_rating (str): Average rating of the movie in question. \n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "    soup = get_html_soup(movie_url)\n",
    "    soup = bs(requests.get(base_url + soup.find('aside', class_='sidebar').find('div', class_='js-csi')['data-src']).text)\n",
    "\n",
    "    li_list = soup.findAll('li')\n",
    "    movie_rating_dict = {}\n",
    "    movie_rating_list = []\n",
    "\n",
    "    for i in range(len(li_list)):\n",
    "\n",
    "        # If there are ratings in this star value\n",
    "        try: \n",
    "            rating_string = li_list[i].find('a')['title'].replace(u'\\xa0', u' ').split(' ')\n",
    "\n",
    "        # If there are not\n",
    "        except TypeError:\n",
    "            rating_string = li_list[i]['title'].replace(u'\\xa0', u' ').split(' ')\n",
    "\n",
    "        # If the Exception was encountered, this replaces 'No' with 0\n",
    "        number_of_ratings = rating_string[0].replace('No', '0')\n",
    "\n",
    "        # If it's the first item, replace the string 'half-★' with '½' like the other rating scheme\n",
    "        star_rating = rating_string[1].replace('half-★', '½')\n",
    "\n",
    "        # Split the star_rating string into a list\n",
    "        star_rating_list = list(star_rating)\n",
    "\n",
    "        # Replace the stars with 1.0 and the '½' with 0.5, convert to floats, sum them\n",
    "        rating = sum([float(star_rating_list[i].replace('★', '1.0').replace('½', '0.5'))\\\n",
    "                  for i in range(len(star_rating_list))])\n",
    "\n",
    "        # Add to dictionary\n",
    "        movie_rating_dict[rating] = number_of_ratings\n",
    "\n",
    "    total = sum([int(item.replace(',', '')) for item in movie_rating_dict.values()])\n",
    "\n",
    "    rating_dict_items = list(movie_rating_dict.items())\n",
    "\n",
    "    for item in rating_dict_items:\n",
    "\n",
    "        movie_rating_dict = {}\n",
    "\n",
    "        rating = item[0]\n",
    "        number_of_ratings = int(item[1].replace(',', ''))\n",
    "        perc_of_total = round(number_of_ratings / total, 4)\n",
    "\n",
    "        movie_rating_dict['rating'] = rating\n",
    "        movie_rating_dict['number_of_ratings'] = number_of_ratings\n",
    "        movie_rating_dict['perc_of_total'] = perc_of_total\n",
    "\n",
    "        movie_rating_list.append(movie_rating_dict)\n",
    "\n",
    "    return movie_rating_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rating': 0.5, 'number_of_ratings': 405, 'perc_of_total': 0.0019},\n",
       " {'rating': 1.0, 'number_of_ratings': 1095, 'perc_of_total': 0.0052},\n",
       " {'rating': 1.5, 'number_of_ratings': 475, 'perc_of_total': 0.0023},\n",
       " {'rating': 2.0, 'number_of_ratings': 3119, 'perc_of_total': 0.0149},\n",
       " {'rating': 2.5, 'number_of_ratings': 2450, 'perc_of_total': 0.0117},\n",
       " {'rating': 3.0, 'number_of_ratings': 15446, 'perc_of_total': 0.074},\n",
       " {'rating': 3.5, 'number_of_ratings': 15391, 'perc_of_total': 0.0738},\n",
       " {'rating': 4.0, 'number_of_ratings': 54193, 'perc_of_total': 0.2597},\n",
       " {'rating': 4.5, 'number_of_ratings': 33010, 'perc_of_total': 0.1582},\n",
       " {'rating': 5.0, 'number_of_ratings': 83083, 'perc_of_total': 0.3982}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_rating_counts = get_movie_rating_counts(lotr_fotr_url)\n",
    "movie_rating_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Snagging the movie description while we're at it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_desc(movie_url):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Given a URL to a movie on letterboxd.com, this function returns the description of the movie.\n",
    "    \n",
    "    Parameters:\n",
    "        movie_url (str): URL to a film on letterboxd.com.\n",
    "        \n",
    "    Returns:\n",
    "        movie_desc (str): Description to the film in question. \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    soup = get_html_soup(movie_url)\n",
    "    \n",
    "    movie_desc = soup.findAll('meta')[3]['content'].strip()\n",
    "    return movie_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Young hobbit Frodo Baggins, after inheriting a mysterious ring from his uncle Bilbo, must leave his home in order to keep it from falling into the hands of its evil creator. Along the way, a fellowship is formed to protect the ringbearer and make sure that the ring arrives at its final destination: Mt. Doom, the only place where it can be destroyed.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_desc = get_movie_desc(lotr_fotr_url)\n",
    "movie_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now that we've got a good selection of information about *The Fellowship of the Ring* let's put it together in one large dictionary. \n",
    "\n",
    "Then we can get started on scraping IMDb for the last few attributes we'll want:\n",
    "* The movie's budget and revenue\n",
    "* The movie's release date\n",
    "\n",
    "Additionally, we're going to want to scrape the movie's genre(s) from either Letterboxd or IMDb, I'm not sure which one just yet though. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = {}\n",
    "movie['title'] = movie_title\n",
    "movie['description'] = movie_desc\n",
    "movie['avg_rating'] = movie_avg_rating\n",
    "movie['cast'] = cast_dict\n",
    "movie['crew'] = crew_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below to see what the movie dictionary looks like\n",
    "# movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's put everything together into a *bigger* dictionary and add a loop to scrape every film on the page!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The true story of one of the worst man-made catastrophes in history: the catastrophic nuclear accident at Chernobyl. A tale of the brave men and women who sacrificed to save Europe from unimaginable disaster.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_movie_desc(base_url + get_movie_url(movies_on_page[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to need some functions here:\n",
    "1. A function that operates at the \"account-level\" to zero-in on a user's ratings\n",
    "2. Get a list of pages of movies to scrape \n",
    "3. Get a list of movies on a single page to scrape\n",
    "4. Scrape a single movie's data given a URL \n",
    "5. Write everything out to a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_movie_data(movie_url, user_movie_rating = None):\n",
    "    \n",
    "    '''\n",
    "    Given a URL to a movie on letterboxd.com, this function returns a dictionary of data about the movie.\n",
    "    \n",
    "    Parameters:\n",
    "        movie_url (str): URL to a film on letterboxd.com.\n",
    "        \n",
    "        user_movie_rating (str/float): Optional parameter; if scraping from a user's ratings page you can pass in that user's rating for the film in question.\n",
    "        Otherwise, if you are only scraping a film's page for its attributes and are not interested in a specific user's rating, disregard. \n",
    "    \n",
    "    Returns:\n",
    "        movie_dict (dict): Nested dictionary that contains data about the movie passed in. \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    movie_dict = {}\n",
    "    movie_url = movie_url\n",
    "\n",
    "    # Attributes from the movie page or already stored in variables\n",
    "    movie_dict['title'] = get_movie_title(movie_url)\n",
    "    movie_dict['url'] = movie_url\n",
    "    movie_dict['genres'] = get_movie_genres(movie_url)\n",
    "    movie_dict['description'] = get_movie_desc(movie_url)\n",
    "    movie_dict['avg_rating'] = get_movie_avg_rating(movie_url)\n",
    "    movie_dict['rating_counts'] = get_movie_rating_counts(movie_url)\n",
    "    \n",
    "    if user_movie_rating:\n",
    "        movie_dict['user_rating'] = user_movie_rating\n",
    "        \n",
    "    movie_dict['cast'] = get_cast_data(movie_url)\n",
    "    movie_dict['crew'] = get_crew_data(movie_url)\n",
    "    \n",
    "    return movie_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_page_ratings(rating_page_url):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Given a URL to a page of user ratings on letterboxd.com, this function returns a list of nested dictionaries\n",
    "    which data about each movie rated on that specific page. \n",
    "    \n",
    "    Parameters: \n",
    "        rating_page_url (str): URL to a page of a user's movie ratings on letterboxd.com.\n",
    "        \n",
    "    Returns:\n",
    "        page_ratings_list (list): List of movies rated by a user on that specific page. \n",
    "        Contains nested dictionaries with data about each film as well as the user's rating for the film. \n",
    "    \n",
    "    '''\n",
    "\n",
    "    soup = get_html_soup(rating_page_url)\n",
    "    base_url = 'https://letterboxd.com/'\n",
    "    \n",
    "    page_ratings_list = []\n",
    "    \n",
    "    try:\n",
    "        movies_on_page = soup.findAll('ul', class_='poster-list -p150 -grid')[0].findAll('li')\n",
    "    except IndexError:\n",
    "        return None\n",
    "\n",
    "    for i in range(len(movies_on_page)):\n",
    "        \n",
    "        # Get the URL for the movie\n",
    "        movie_url = base_url + get_movie_url(movies_on_page[i])\n",
    "\n",
    "        # Get the user's rating for the movie\n",
    "        user_movie_rating = get_user_movie_rating(movies_on_page[i])\n",
    "        \n",
    "        # Scrape the movie data and also include the user's rating for the movie\n",
    "        movie_dict = scrape_movie_data(movie_url, user_movie_rating)\n",
    "        \n",
    "        # Append the returned dictionary to the list for this page\n",
    "        page_ratings_list.append(movie_dict)\n",
    "\n",
    "    return page_ratings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pages_to_scrape(account_name):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Given an account name on letterboxd.com, this function returns the number of pages of movie ratings there are to\n",
    "    scrape through for that account. \n",
    "    \n",
    "    Parameters:\n",
    "        account_name (str): Name of an account on letterboxd.com to gather movie ratings from. \n",
    "        \n",
    "    Returns: \n",
    "        pages_to_scrape (int): Number of pages of movie ratings this user has that will need to be scraped. \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    base_url = 'https://letterboxd.com/'\n",
    "    account_name = account_name.lower().strip()\n",
    "    \n",
    "    # Everyone has at least one page, even if they have no ratingns\n",
    "    ratings_url = base_url + account_name.lower() + '/films/ratings/by/rating/page/1'\n",
    "    soup = get_html_soup(ratings_url)\n",
    "    pages_to_scrape = 1\n",
    "\n",
    "    try:\n",
    "        paginate_pages = soup.findAll('div', class_='paginate-pages')[0]\n",
    "\n",
    "    except IndexError:\n",
    "        return pages_to_scrape\n",
    "\n",
    "    pages_to_scrape = int(paginate_pages.findAll('li')[-1].text)\n",
    "    return pages_to_scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_account_ratings(account_to_scrape):\n",
    "\n",
    "    '''\n",
    "    \n",
    "    Given an account name on letterboxd.com, this function returns a dictionary which contains data about all the films\n",
    "    the user has rated. \n",
    "    \n",
    "    The dictionary returned is nested - each movie rated is an entry in a list and each entry in the list itself contains \n",
    "    a multi-level data structure to include cast, crew, the moving's average rating, etc.\n",
    "    \n",
    "    Parameters: \n",
    "        account_to_scrape (str): Name of an account on letterboxd.com to gather movie ratings from. \n",
    "        \n",
    "    Returns:\n",
    "        movie_ratings (dict): Nested dictionary that contains data about movies rated by the user specified in account_name. \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    movie_ratings = {}\n",
    "    movies_by_page_list = []\n",
    "    movies_rated_list = []\n",
    "\n",
    "    account_name = account_to_scrape.lower().strip()\n",
    "    base_url = 'https://letterboxd.com/'\n",
    "    account_url = base_url + account_name\n",
    "    account_ratings_url = account_url + '/films/ratings/by/rating/'\n",
    "    \n",
    "    movie_ratings['account'] = account_name\n",
    "    movie_ratings['account_url'] = account_url\n",
    "    movie_ratings['account_ratings_url'] = account_ratings_url\n",
    "    \n",
    "    pages_to_scrape = get_pages_to_scrape(account_name)\n",
    "    \n",
    "    for i in range(pages_to_scrape):\n",
    "        page_dict = {}\n",
    "        \n",
    "        page_number = str(i+1)\n",
    "    \n",
    "        ratings_url = base_url + account_name + '/films/ratings/by/rating/page/'+page_number\n",
    "        page_ratings = scrape_page_ratings(ratings_url)\n",
    "        \n",
    "        page_dict['page'] = page_number\n",
    "        page_dict['movies_on_page'] = page_ratings\n",
    "        \n",
    "        movies_by_page_list.append(page_dict)\n",
    "    \n",
    "    if not page_ratings:\n",
    "        movie_ratings['movies_rated'] = None\n",
    "        return movie_ratings\n",
    "    \n",
    "    for i in range(len(movies_by_page_list)):\n",
    "        for j in range(len(movies_by_page_list[i]['movies_on_page'])):\n",
    "            movies_rated_list.append(movies_by_page_list[i]['movies_on_page'][j])\n",
    "            \n",
    "    # The following code is equivalent to the nested FOR loops above using list comprehensions\n",
    "    # The FOR loop is significantly slower in execution than the list comprehension - but has one key advantage\n",
    "    # The FOR loop is very easily read, whereas the nested list comprehension is a rather convoluted piece of code\n",
    "    '''\n",
    "    movies_rated_list = \\\n",
    "    [movies_by_page_list[i]['movies_on_page'][j] \\\n",
    "     for j in range(len(movies_by_page_list[i]['movies_on_page'])) \\\n",
    "     for i in range(len(movies_by_page_list))]\n",
    "    '''\n",
    "    \n",
    "    # For a look at why I'm choosing readability and simplicity over effectiveness, run one small piece of code:\n",
    "    # import this\n",
    "        \n",
    "    movie_ratings['movies_rated'] = movies_rated_list\n",
    "    \n",
    "    return movie_ratings     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dict_to_json(filename, data, path_to_file = None, encoding = 'utf-8'):\n",
    "    \n",
    "    '''\n",
    "    Writes a dictionary out to a JSON file.\n",
    "    \n",
    "    Parameters:\n",
    "        filename (str): Name of the file, including the .json extension. \n",
    "        If you forget the .json extension, the program will add it automatically.\n",
    "        \n",
    "        data (dict): Dictionary of data to be written out to a JSON file.\n",
    "        \n",
    "        path_to_file (str): Optional parameter; specify a path to the file. If the path does not exist, it will be created. \n",
    "        If you do not specify a path, the program will use the current working directory. \n",
    "        \n",
    "        encoding (str): Optional parameter; file encoding. If you do not specify an encoding codec, utf-8 will be used. \n",
    "        \n",
    "    Returns:\n",
    "        None.\n",
    "        \n",
    "    Outputs:\n",
    "        JSON file at the location specified. \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    if not os.path.isdir(path_to_file):\n",
    "        os.mkdir(path_to_file)\n",
    "        \n",
    "    path_to_file = reduce(lambda x, y: x if x is not None else y, [path_to_file, os.getcwd().replace('\\\\', '/')])\n",
    "    \n",
    "    if '.json' not in filename:\n",
    "        filename = filename + '.json'\n",
    "        \n",
    "    if path_to_file[-1:] != '/':\n",
    "        path_to_file = path_to_file + '/'\n",
    "        \n",
    "    full_file_path = path_to_file + '/' + filename\n",
    "    \n",
    "    with open(full_file_path, 'w', encoding = encoding) as file:\n",
    "        json.dump(data, file, ensure_ascii = False, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aragorn_ratings = scrape_account_ratings('aragorn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dict_to_json('aragorn.json', aragorn_ratings, 'movie_jsons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write_json_to_file('movie_jsons', 'elrond.json', scrape_account_ratings('elrond'))\n",
    "#write_json_to_file('movie_jsons', 'frodo.json', scrape_account_ratings('frodo'))\n",
    "#write_json_to_file('movie_jsons', 'gandalf.json', scrape_account_ratings('gandalf'))\n",
    "#write_json_to_file('movie_jsons', 'gimli.json', scrape_account_ratings('gimli'))\n",
    "#write_json_to_file('movie_jsons', 'legolas.json', scrape_account_ratings('legolas'))\n",
    "#write_json_to_file('movie_jsons', 'samwise.json', scrape_account_ratings('samwise'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Uncomment to create the linneburg_ratings dictionary\n",
    "# Note: This process takes roughly 15 minutes to complete (~1 minute, 15 seconds per page)\n",
    "# linneburg_ratings = scrape_account_ratings('joshlinneburg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Uncomment to see what the linneburg_ratings dictionary looks like\n",
    "# linneburg_ratings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
